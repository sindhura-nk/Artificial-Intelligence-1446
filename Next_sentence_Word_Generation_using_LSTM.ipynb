{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBqR6jsO8LVncjcKQujSrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhura-nk/Artificial-Intelligence-1446/blob/main/Next_sentence_Word_Generation_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buisness Scenario: Build a model that can predict the next words when some words are provided to it."
      ],
      "metadata": {
        "id": "loGMZQEnOmIZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpXqHcO9OhFT"
      },
      "outputs": [],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "JXYMd7UGPFz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary libraries\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(action='ignore')\n",
        "\n",
        "# Preprocess the text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # creates work tokens, number sequences\n",
        "from keras.preprocessing import sequence # padding\n",
        "# Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input,Dense,LSTM,Embedding"
      ],
      "metadata": {
        "id": "b6L9lVpQPK0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOad the dataset"
      ],
      "metadata": {
        "id": "UVsMF1h7P6v2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/Harry Potter and the Sorcerer's Sto.txt\",'r') as file:\n",
        "  data = file.read()\n",
        "print(data[:50])"
      ],
      "metadata": {
        "id": "kbLoc3ZOP5P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:50]"
      ],
      "metadata": {
        "id": "XoEmnPs-U9RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using Keras Tokenizer here. Few points are discussed below related to fit_on_texts method and texts_to_sequences method:\n",
        "tokenizer.fit_on_texts(texts) : Builds the word index (vocabulary) from your dataset.\n",
        "\n",
        "It looks at the list of texts you give it. It assigns a unique integer index to each unique word.\n",
        "The most frequent word gets index 1, the next most frequent 2, and so on. Index 0 is reserved for padding.\n",
        "\n",
        "Example: texts = [\"The wizard cast a spell\", \"The spell was powerful\"]\n",
        "tokenizer.fit_on_texts(texts)\n",
        "print(tokenizer.word_index)\n",
        "Output: {'the': 1, 'spell': 2, 'wizard': 3, 'cast': 4, 'a': 5, 'was': 6, 'powerful': 7}\n",
        "tokenizer.texts_to_sequences(texts): Converts your texts into sequences of integers based on the word index created by fit_on_texts.\n",
        "\n",
        "Example: sequences = tokenizer.texts_to_sequences([\"The wizard cast a spell\"])\n",
        "print(sequences)\n",
        "Output: [[1, 3, 4, 5, 2]]"
      ],
      "metadata": {
        "id": "ep9UIcV7SF7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# apply the tokenizer on respective words\n",
        "texts = [\"The wizard cast a spell\", \"The spell was powerful\"]\n",
        "tokenizer.fit_on_texts(texts) # this is going to develop tokens and their frequency count\n",
        "# the : 2\n",
        "# wizard: 1\n",
        "# cast: 1\n",
        "# a : 1\n",
        "# spell:2\n",
        "print(tokenizer.word_index)\n",
        "# word indexing: the:1, spell:2, wizard:3, cast:4, a:5.....\n"
      ],
      "metadata": {
        "id": "DabAwCKcQGuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we want to give this text to the model\n",
        "# [[1,3,4,5,2],[1,2,6,7]]\n",
        "tokenizer.texts_to_sequences(texts)"
      ],
      "metadata": {
        "id": "bo92BjEpSjuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit on texts - pass the data\n",
        "tokenizer.fit_on_texts([data])\n",
        "word_ind = tokenizer.word_index\n",
        "word_ind"
      ],
      "metadata": {
        "id": "3g_ULXMwTQ69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index = {value:key for key,value in word_ind.items()}\n",
        "reverse_word_index"
      ],
      "metadata": {
        "id": "z3TAwW1sTk09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text on sequences"
      ],
      "metadata": {
        "id": "qyfsnwVGT6pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_length = len(word_ind) + 1\n",
        "# to reserve for padding"
      ],
      "metadata": {
        "id": "Tlytk_z-T2FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_length"
      ],
      "metadata": {
        "id": "cswAYtKqUPA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in data.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  # [4,5,6,7]\n",
        "  for i in range(1,len(token_list)): # for i in range(1,4)\n",
        "    n_gram_sequence = token_list[:i+1] # token_list[0:2] = 0th index,1st index\n",
        "    # token_list[0:3] = 0th index,1st index,2nd index\n",
        "    # token_list[0:4] = 0th index, 1st index, 2nd index, 3rd index\n",
        "    input_sequences.append(n_gram_sequence) # [[4,5],[4,5,6],[4,5,6,7]]\n",
        "print(input_sequences[:15])"
      ],
      "metadata": {
        "id": "3KlsO4zdUQW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## padding to bring all the ngram tokens to same size. to bring all the setences to same length"
      ],
      "metadata": {
        "id": "ogUQRWZSWHrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max([90,89,77])"
      ],
      "metadata": {
        "id": "FkS6MHrqWeTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(lines) for lines in input_sequences])\n",
        "\n",
        "input_sequences = sequence.pad_sequences(input_sequences,maxlen=max_length)\n",
        "input_sequences[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noq6wVJAV-V5",
        "outputId": "7d132fc4-e7e2-41da-c2c2-179d278b9c15"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   7, 121],\n",
              "       [  0,   0,   0, ...,   7, 121,   2],\n",
              "       [  0,   0,   0, ..., 121,   2,   1],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 253, 220,   6],\n",
              "       [  0,   0,   0, ..., 220,   6, 612],\n",
              "       [  0,   0,   0, ...,   6, 612, 316]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dW0VGztWp6N",
        "outputId": "d4fad38d-36cf-44b1-f5a8-719ffc070683"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separate x and y"
      ],
      "metadata": {
        "id": "6Zm4YaR-W09H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = input_sequences[:,:-1]\n",
        "y = input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "rkosZIkZWu6m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t117PzeZXMX2",
        "outputId": "94c0ef1f-1d8d-48a8-d892-8fcfff57d71e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,   7],\n",
              "       [  0,   0,   0, ...,   0,   7, 121],\n",
              "       [  0,   0,   0, ...,   7, 121,   2],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   1, 144],\n",
              "       [  0,   0,   0, ...,   1, 144,  63],\n",
              "       [  0,   0,   0, ...,   0,   0, 150]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7xsvdniXNr6",
        "outputId": "e152c776-fcba-4dc3-8950-853f6bea3235"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 121,    2,    1,  634,  158,   38,  144,   63, 1049,    2],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSh3OjkVYsNo",
        "outputId": "dd340cd6-8ed1-4fc8-9850-2599a79148cc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74892,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to use categorical_crossentropy, then convert y into y cateogrical.\n",
        "    y_cat = to_categorical(y)"
      ],
      "metadata": {
        "id": "5dlY3GP0Xf9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Buidling"
      ],
      "metadata": {
        "id": "q9IBBMT2XU7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Provide the input as max length indicating total number of sentences\n",
        "model.add(Input((max_length,)))\n",
        "# Add the layers\n",
        "model.add(Embedding(input_dim=total_length,output_dim=300,trainable=False))\n",
        "model.add(LSTM(200,return_sequences=True,dropout=0.3)) # return sequences will provide the sequences to next LSTM layer\n",
        "model.add(LSTM(150,dropout=0.2))\n",
        "# Add one Hidden layer\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "# Add output layer\n",
        "model.add(Dense(total_length, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "iZPOPXN2XRip"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HAczxrh9Yrle"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='accuracy',patience=5)"
      ],
      "metadata": {
        "id": "7kzo9KTvZPE0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = model.fit(x,y,validation_split=0.2,epochs=10,callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMICcoLiZTC8",
        "outputId": "866ca646-963f-40df-e004-f1d1ee3f0cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1382/1873\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.0448 - loss: 7.0611"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "def generate_text(user_text, next_words=10):\n",
        "    for _ in range(next_words):\n",
        "        # preparing our user text ready for the model\n",
        "        token_list = [tokenizer.word_ind.get(w, 0) for w in word_tokenize(user_text.lower())]\n",
        "        token_list = sequence.pad_sequences([token_list],maxlen=max_length-1)\n",
        "        # give the proceesed text to model for prediction of next 50words\n",
        "        predicted_probs = model.predict(token_list.reshape(1, max_length-1), verbose=0)\n",
        "        predicted = np.argmax(predicted_probs, axis=-1) # it gives you the index of next word\n",
        "        output_word = reverse_word_index.get(predicted[0], '') # convert the index into word using index_word\n",
        "        user_text += ' ' + output_word\n",
        "        # user_text = user_text + output_word\n",
        "    return user_text"
      ],
      "metadata": {
        "id": "up5Y3rRMZY-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"The Wizard is\"))"
      ],
      "metadata": {
        "id": "7t7Z4OECbS6t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}