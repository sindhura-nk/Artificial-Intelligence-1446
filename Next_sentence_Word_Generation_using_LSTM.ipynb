{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmlR+X57gprV2m+OdQD3pZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhura-nk/Artificial-Intelligence-1446/blob/main/Next_sentence_Word_Generation_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buisness Scenario: Build a model that can predict the next words when some words are provided to it."
      ],
      "metadata": {
        "id": "loGMZQEnOmIZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpXqHcO9OhFT",
        "outputId": "e7a475b8-ed79-4ed4-d402-6aeb2e28cc54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXYMd7UGPFz1",
        "outputId": "7a29ee58-6905-467c-9666-b4d13caf35d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary libraries\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(action='ignore')\n",
        "\n",
        "# Preprocess the text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # creates work tokens, number sequences\n",
        "from keras.preprocessing import sequence # padding\n",
        "# Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input,Dense,LSTM,Embedding"
      ],
      "metadata": {
        "id": "b6L9lVpQPK0C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOad the dataset"
      ],
      "metadata": {
        "id": "UVsMF1h7P6v2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/Harry Potter and the Sorcerer's Sto.txt\",'r') as file:\n",
        "  data = file.read()\n",
        "print(data[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbLoc3ZOP5P8",
        "outputId": "e4885507-f5c0-4c2e-e37a-f677bd2c9cbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harry Potter and the Sorcerer's Stone \n",
            "\n",
            "CHAPTER ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XoEmnPs-U9RO",
        "outputId": "a9dea338-7236-4caa-c157-86e17ff303d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Harry Potter and the Sorcerer's Stone \\n\\nCHAPTER ON\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using Keras Tokenizer here. Few points are discussed below related to fit_on_texts method and texts_to_sequences method:\n",
        "tokenizer.fit_on_texts(texts) : Builds the word index (vocabulary) from your dataset.\n",
        "\n",
        "It looks at the list of texts you give it. It assigns a unique integer index to each unique word.\n",
        "The most frequent word gets index 1, the next most frequent 2, and so on. Index 0 is reserved for padding.\n",
        "\n",
        "Example: texts = [\"The wizard cast a spell\", \"The spell was powerful\"]\n",
        "tokenizer.fit_on_texts(texts)\n",
        "print(tokenizer.word_index)\n",
        "Output: {'the': 1, 'spell': 2, 'wizard': 3, 'cast': 4, 'a': 5, 'was': 6, 'powerful': 7}\n",
        "tokenizer.texts_to_sequences(texts): Converts your texts into sequences of integers based on the word index created by fit_on_texts.\n",
        "\n",
        "Example: sequences = tokenizer.texts_to_sequences([\"The wizard cast a spell\"])\n",
        "print(sequences)\n",
        "Output: [[1, 3, 4, 5, 2]]"
      ],
      "metadata": {
        "id": "ep9UIcV7SF7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# apply the tokenizer on respective words\n",
        "texts = [\"The wizard cast a spell\", \"The spell was powerful\"]\n",
        "tokenizer.fit_on_texts(texts) # this is going to develop tokens and their frequency count\n",
        "# the : 2\n",
        "# wizard: 1\n",
        "# cast: 1\n",
        "# a : 1\n",
        "# spell:2\n",
        "print(tokenizer.word_index)\n",
        "# word indexing: the:1, spell:2, wizard:3, cast:4, a:5.....\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DabAwCKcQGuo",
        "outputId": "866c1429-6ad1-4015-c961-3411bf687aa1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'spell': 2, 'wizard': 3, 'cast': 4, 'a': 5, 'was': 6, 'powerful': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we want to give this text to the model\n",
        "# [[1,3,4,5,2],[1,2,6,7]]\n",
        "tokenizer.texts_to_sequences(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo92BjEpSjuX",
        "outputId": "8c808985-65d2-49e5-f3de-f259264db075"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 3, 4, 5, 2], [1, 2, 6, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit on texts - pass the data\n",
        "tokenizer.fit_on_texts([data])\n",
        "word_ind = tokenizer.word_index\n",
        "word_ind"
      ],
      "metadata": {
        "id": "3g_ULXMwTQ69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index = {value:key for key,value in word_ind.items()}\n",
        "reverse_word_index"
      ],
      "metadata": {
        "id": "z3TAwW1sTk09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text on sequences"
      ],
      "metadata": {
        "id": "qyfsnwVGT6pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_length = len(word_ind) + 1\n",
        "# to reserve for padding"
      ],
      "metadata": {
        "id": "Tlytk_z-T2FT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cswAYtKqUPA7",
        "outputId": "6f0741f5-2cc7-473f-e89f-05bb3ee85613"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6032"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in data.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  # [4,5,6,7]\n",
        "  for i in range(1,len(token_list)): # for i in range(1,4)\n",
        "    n_gram_sequence = token_list[:i+1] # token_list[0:2] = 0th index,1st index\n",
        "    # token_list[0:3] = 0th index,1st index,2nd index\n",
        "    # token_list[0:4] = 0th index, 1st index, 2nd index, 3rd index\n",
        "    input_sequences.append(n_gram_sequence) # [[4,5],[4,5,6],[4,5,6,7]]\n",
        "print(input_sequences[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KlsO4zdUQW0",
        "outputId": "8d40813e-3503-47d6-9b76-dcbc4e844139"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7, 121], [7, 121, 2], [7, 121, 2, 1], [7, 121, 2, 1, 634], [7, 121, 2, 1, 634, 158], [611, 38], [1, 144], [1, 144, 63], [1, 144, 63, 1049], [150, 2], [150, 2, 253], [150, 2, 253, 220], [150, 2, 253, 220, 6], [150, 2, 253, 220, 6, 612], [150, 2, 253, 220, 6, 612, 316]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## padding to bring all the ngram tokens to same size. to bring all the setences to same length"
      ],
      "metadata": {
        "id": "ogUQRWZSWHrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max([90,89,77])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkS6MHrqWeTW",
        "outputId": "8c5607f9-d637-436c-a000-f50180ef0bfb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(lines) for lines in input_sequences])\n",
        "\n",
        "input_sequences = sequence.pad_sequences(input_sequences,maxlen=max_length)\n",
        "input_sequences[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noq6wVJAV-V5",
        "outputId": "8af4d960-69ab-4ea7-ec32-ca05d3bf43bb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   7, 121],\n",
              "       [  0,   0,   0, ...,   7, 121,   2],\n",
              "       [  0,   0,   0, ..., 121,   2,   1],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 253, 220,   6],\n",
              "       [  0,   0,   0, ..., 220,   6, 612],\n",
              "       [  0,   0,   0, ...,   6, 612, 316]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dW0VGztWp6N",
        "outputId": "6479dd51-43a2-40bc-c2e6-e5a68a39dd09"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separate x and y"
      ],
      "metadata": {
        "id": "6Zm4YaR-W09H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = input_sequences[:,:-1]\n",
        "y = input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "rkosZIkZWu6m"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t117PzeZXMX2",
        "outputId": "7cf2a9f4-e613-4720-c99f-019955d1418a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,   7],\n",
              "       [  0,   0,   0, ...,   0,   7, 121],\n",
              "       [  0,   0,   0, ...,   7, 121,   2],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   1, 144],\n",
              "       [  0,   0,   0, ...,   1, 144,  63],\n",
              "       [  0,   0,   0, ...,   0,   0, 150]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7xsvdniXNr6",
        "outputId": "76fec61b-cb8b-4725-b405-805f03ebf097"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 121,    2,    1,  634,  158,   38,  144,   63, 1049,    2],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSh3OjkVYsNo",
        "outputId": "da20117d-2c34-4a14-c4e3-003038c01f82"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74892,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to use categorical_crossentropy, then convert y into y cateogrical.\n",
        "    y_cat = to_categorical(y)"
      ],
      "metadata": {
        "id": "5dlY3GP0Xf9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Buidling"
      ],
      "metadata": {
        "id": "q9IBBMT2XU7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Provide the input as max length indicating total number of sentences\n",
        "model.add(Input((max_length,)))\n",
        "# Add the layers\n",
        "model.add(Embedding(input_dim=total_length,output_dim=300,trainable=False))\n",
        "model.add(LSTM(200,return_sequences=True,dropout=0.3)) # return sequences will provide the sequences to next LSTM layer\n",
        "model.add(LSTM(150,dropout=0.2))\n",
        "# Add one Hidden layer\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "# Add output layer\n",
        "model.add(Dense(total_length, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "iZPOPXN2XRip"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HAczxrh9Yrle"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='accuracy',patience=5)"
      ],
      "metadata": {
        "id": "7kzo9KTvZPE0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = model.fit(x,y,validation_split=0.2,epochs=10,callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMICcoLiZTC8",
        "outputId": "d403eba1-6b76-459b-f6b4-de89e27bf741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m 375/1873\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26:39\u001b[0m 1s/step - accuracy: 0.0378 - loss: 7.3815"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "def generate_text(user_text, next_words=10):\n",
        "    for _ in range(next_words):\n",
        "        # preparing our user text ready for the model\n",
        "        token_list = [tokenizer.word_ind.get(w, 0) for w in word_tokenize(user_text.lower())]\n",
        "        token_list = sequence.pad_sequences([token_list],maxlen=max_length-1)\n",
        "        # give the proceesed text to model for prediction of next 50words\n",
        "        predicted_probs = model.predict(token_list.reshape(1, max_length-1), verbose=0)\n",
        "        predicted = np.argmax(predicted_probs, axis=-1) # it gives you the index of next word\n",
        "        output_word = reverse_word_index.get(predicted[0], '') # convert the index into word using index_word\n",
        "        user_text += ' ' + output_word\n",
        "        # user_text = user_text + output_word\n",
        "    return user_text"
      ],
      "metadata": {
        "id": "up5Y3rRMZY-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}